---
---



@INPROCEEDINGS{11240350,
  abbr={ITW 2025},
  author={Moeini, AmirPouya and Fàbregas, Albert Guillén i},
  booktitle={2025 IEEE Information Theory Workshop (ITW)}, 
  title={Dual-Domain Exponent of Maximum Mutual Information Decoding}, 
  year={2025},
  volume={},
  number={},
  pages={810-814},
  url={https://ieeexplore.ieee.org/document/11240350},
  abstract={This paper provides a dual domain derivation of the error exponent of maximum mutual information (MMI) decoding with constant composition codes, showing it coincides with that of maximum likelihood decoding for discrete memoryless channels. The analysis is further extended to joint source-channel coding, demonstrating that the generalized MMI decoder achieves the same random coding error exponent as the maximum a posteriori decoder.},
  doi={10.1109/ITW62417.2025.11240350}}




@INPROCEEDINGS{11240453,
  abbr={ITW 2025},
  author={Moeini, AmirPouya and Fàbregas, Albert Guillén i},
  booktitle={2025 IEEE Information Theory Workshop (ITW)}, 
  title={Class-Based Expurgation Attains Csiszár’s Expurgated Source-Channel Exponent}, 
  year={2025},
  volume={},
  number={},
  pages={794-797},
  abstract={This paper studies expurgated error exponents for joint source-channel coding for discrete memoryless sources and channels. We consider a partition of the source messages into classes, where the codeword distributions depend on the class. We show that two carefully chosen classes suffice to achieve Csiszár’s expurgated exponent.},
  keywords={Conferences;Encoding},
  url={https://ieeexplore.ieee.org/document/11240453},
  doi={10.1109/ITW62417.2025.11240453}}






@INPROCEEDINGS{izs2026,
  abbr={IZS 2026},
  author={Moeini, AmirPouya and Fàbregas, Albert Guillén i},
  booktitle={2026 International Zurich Seminar on Information and Communication}, 
  title={Two-Class Joint Source-Channel Coding: Expurgated Exponents with i.i.d. Distributions}, 
  year={2026},
  volume={},
  number={},
  pages={},
  url={},  abstract={This paper studies expurgated exponents for joint source-channel coding of discrete memoryless sources and channels under i.i.d. random coding. We show that a two-class partitioning of source sequences, where the codeword distribution depends on the source type, achieves an exponent at least as high as that of optimal single-class coding, in which the codeword distribution is independent of the source message.}
}
